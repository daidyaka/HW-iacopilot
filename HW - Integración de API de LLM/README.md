# Tarea: Chatbot con Capacidad de B√∫squeda en Internet y Respuestas en Streaming

## Objetivo

Desarrollar un chatbot que funcione desde la consola, manteniendo la memoria de la conversaci√≥n durante su ejecuci√≥n y con la capacidad de realizar b√∫squedas en Internet para enriquecer sus respuestas. Este chatbot debe tambi√©n proporcionar respuestas en streaming y citar las fuentes de donde extrajo la informaci√≥n.

## Requerimientos

1. **Interfaz de Consola:** El chatbot debe operar a trav√©s de una interfaz de consola, permitiendo a los usuarios hacer preguntas y recibir respuestas en tiempo real.

2. **Memoria de Conversaci√≥n:** Durante el runtime, el chatbot debe recordar el historial de la conversaci√≥n para utilizarlo como contexto en interacciones futuras.

3. **B√∫squeda en Internet:** Implementar function calling para realizar b√∫squedas en Google usando la API de [https://serper.dev/](https://serper.dev/), que proporciona cr√©ditos gratuitos para b√∫squedas. El chatbot debe procesar informaci√≥n de los primeros 5 enlaces que resulten m√°s relevantes para la pregunta del usuario.

4. **Respuestas en Streaming:** Las respuestas deben ser proporcionadas en tiempo real mientras se procesa la informaci√≥n recopilada, incluyendo una indicaci√≥n de las fuentes de datos conforme se obtienen y procesan.

5. **Citar Fuentes:** Al final de cada respuesta, el chatbot debe proporcionar los enlaces o referencias de las p√°ginas de donde ha extra√≠do la informaci√≥n, asegurando la transparencia y permitiendo al usuario acceder a la fuente directamente.

## Especificaciones T√©cnicas

- **API de B√∫squeda:** Utilizar la API de Serper.dev para realizar b√∫squedas en Google y obtener enlaces relevantes.
  
- **Extracci√≥n de Texto:** Desarrollar un m√≥dulo que visite cada uno de los primeros 5 enlaces recuperados y extraiga el texto principal de estas p√°ginas.

- **Integraci√≥n LLM:** Configurar la interacci√≥n con un modelo de lenguaje adecuado que pueda tomar tanto el historial de la conversaci√≥n como los datos extra√≠dos de Internet para generar respuestas coherentes y contextuales.

## Pruebas Automatizadas

Crear pruebas automatizadas que verifiquen la funcionalidad de cada componente, incluyendo la capacidad de realizar b√∫squedas efectivas, la extracci√≥n correcta del texto, y la generaci√≥n adecuada de respuestas por parte del LLM.

## Ejemplo de Uso

```bash
> Usuario: ¬øC√≥mo puedo plantar un √°rbol de manzanas?

> Chatbot: ** B√∫squeda en internet **

> Chatbot: Seg√∫n un art√≠culo en GardeningKnowHow, el mejor momento para plantar √°rboles de manzana es al inicio de la primavera. Tambi√©n encontr√© informaci√≥n relevante en WikiHow y PlantingTutorial.com.

Referencias:
- [GardeningKnowHow](https://gardeningknowhow.com/apple-tree)

- [WikiHow](https://wikihow.com/plant-apple-trees)

- [PlantingTutorial.com](https://plantingtutorial.com/apple-trees).
```

## Entrega

- C√≥digo fuente completo del chatbot.
- Documentaci√≥n que describa c√≥mo opera el sistema, incluyendo instrucciones para ejecutar el chatbot y las pruebas.
- Archivo con pruebas unitarias.

## ‚öôÔ∏è Requerimientos T√©cnicos de Software

Para poder realizar esta tarea en su computadora personal, los estudiantes deben asegurarse de contar con lo siguiente:

- [Python 3.10 o superior](https://www.python.org/downloads/) instalado y agregado al `PATH`.  
- [Git](https://git-scm.com/downloads) instalado (para clonar el repositorio y cambiar de rama).  
- Entorno virtual creado con [`venv`](https://docs.python.org/3/library/venv.html) o similar:  
```bash
  python -m venv .venv
```

* Archivo `.env` en la ra√≠z del proyecto con las siguientes variables:

```bash
  SERPER_API_KEY=tu_clave_serper
  OPENAI_API_KEY=tu_clave_llm
  MODEL=gpt-4o-mini
```
* Dependencias de Python instaladas con `pip install -r requirements.txt`, entre ellas:

  * [httpx](https://www.python-httpx.org/) ‚Üí Peticiones HTTP as√≠ncronas.
  * [trafilatura](https://pypi.org/project/trafilatura/) ‚Üí Extracci√≥n de texto de p√°ginas web.
  * [rich](https://pypi.org/project/rich/) ‚Üí Salida formateada y streaming en consola.
  * [python-dotenv](https://pypi.org/project/python-dotenv/) ‚Üí Manejo de variables de entorno.
  * [pydantic](https://docs.pydantic.dev/) ‚Üí Validaci√≥n y modelado de datos.
  * [pytest](https://docs.pytest.org/) y [pytest-asyncio](https://pypi.org/project/pytest-asyncio/) ‚Üí Pruebas automatizadas.
  * [respx](https://pypi.org/project/respx/) ‚Üí Mock de peticiones HTTP en pruebas.
  * [OpenAI SDK para Python](https://pypi.org/project/openai/) ‚Üí Integraci√≥n con el modelo de lenguaje.

---

## ‚ñ∂Ô∏è C√≥mo ejecutar el chatbot

1) Crear y activar entorno virtual:

```bash
python -m venv .venv
.venv\Scripts\activate
```

2) Instalar dependencias:

```bash
pip install -r requirements.txt
```

3) Configurar variables de entorno: copie `.env.example` a `.env` y complete sus claves.

```bash
copy .env.example .env
# Editar .env y agregar SERPER_API_KEY y OPENAI_API_KEY
```

4) Ejecutar desde consola:

```bash
python run_chatbot.py
```

El chatbot mantiene la memoria durante la sesi√≥n, decide con function calling si debe buscar en internet (Serper.dev) y muestra el progreso de fuentes procesadas. La respuesta del LLM se transmite en streaming y al final se listan las referencias.

## üß™ Ejecutar pruebas

```bash
pytest -q
```

Las pruebas cubren:
- B√∫squeda (Serper) y parseo de resultados.
- Extracci√≥n de texto (scraper) con callback de progreso.
- Orquestaci√≥n del flujo en consola con un `FakeLLM`.

## Estructura del proyecto

- src/chatbot/config.py ‚Üí carga de configuraci√≥n (.env)
- src/chatbot/search.py ‚Üí integraci√≥n Serper (httpx)
- src/chatbot/scrape.py ‚Üí extracci√≥n con trafilatura
- src/chatbot/llm.py ‚Üí adapter OpenAI con function calling y streaming
- src/chatbot/console.py ‚Üí REPL de consola con Rich y memoria
- run_chatbot.py ‚Üí punto de entrada
- tests/ ‚Üí pruebas con pytest, pytest-asyncio, respx